{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index constituents\n",
    "(not everything is up-to-date, we use the Sharadar SF1 database)\n",
    "\n",
    "Sometimes (especially for long strategies), I want to limit my focus to the largest X stocks. The high-market-cap stocks are less likely to be manipulated, more liquid and actually profitable companies. However I don't care what is exactly in the S&P500. I care only about marketcap and liquidity. So I also don't need a day-by-day update. Quarterly is fine.\n",
    "\n",
    "The goal is to create a list of stocks of the largest N market caps. However we will apply more rules:\n",
    "\n",
    "* Must have market cap\n",
    "* Must have a SIC code\n",
    "* Must be headquartered in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, time, timedelta\n",
    "from times import get_market_dates, get_market_calendar, last_trading_date_before\n",
    "from data import get_data\n",
    "from tickers import get_tickers\n",
    "from polygon.rest import RESTClient\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"../data/polygon/\"\n",
    "\n",
    "START_DATE =date(2003, 11, 1) # MUST BE 1st of FEB, MAY, AUG or NOV\n",
    "END_DATE = date(2023, 8, 1)\n",
    "\n",
    "with open(DATA_PATH + \"secret.txt\") as f:\n",
    "    KEY = next(f).strip()\n",
    "\n",
    "client = RESTClient(api_key=KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fundamentals create a list of historical top N market cap stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "market_cap = pd.read_csv('../data/other/sharadar_processed.csv')\n",
    "market_cap.date = pd.to_datetime(market_cap.date).dt.date\n",
    "market_cap = market_cap[market_cap['country'] == 'US'] # Filter out ADRs\n",
    "market_cap = market_cap[~market_cap['sic'].isna()] # Filter out tickers with no SIC code\n",
    "\n",
    "dates_and_IDs = {}\n",
    "\n",
    "for day in pd.date_range(START_DATE, END_DATE, freq='3MS').date:\n",
    "    market_cap_day = market_cap[(market_cap['date'] <= day) & (market_cap['date'] > day - timedelta(days=90))]\n",
    "    market_cap_day = market_cap_day[~market_cap_day['ID'].duplicated(keep='last')]\n",
    "    market_cap_day_sorted = market_cap_day.sort_values(by='marketcap_M', ascending=False)\n",
    "\n",
    "    top_market_cap_tickers = market_cap_day_sorted['ID'].head(N).values.tolist()\n",
    "    dates_and_IDs[day.isoformat()] = top_market_cap_tickers\n",
    "\n",
    "with open(f'../output/universes/TOP_{N}.json', 'w') as f: \n",
    "    json.dump(dates_and_IDs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the most recent list, we need a helper function as the universe does not have tickers for every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/universes/TOP_500.json', 'r') as f: \n",
    "    largest_stocks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_value(dictionary, day):\n",
    "    \"\"\"Get the value corresponding to the latest key before <day> in a dictionary\"\"\"\n",
    "    dates = [date.fromisoformat(day) for day in dictionary.keys()]\n",
    "    key = max(filter(lambda x: x < day, dates))\n",
    "    return dictionary[key.isoformat()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL-2003-09-10', 'MSFT-2003-09-10', 'GOOG-2004-08-19']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_latest_value(largest_stocks, date(2022, 5, 2))[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current S&P500 vs Top 500\n",
    "What is the difference between the real S&P500 and the list we created? To get the current S&P500 holdings, I use this [link](https://www.slickcharts.com/sp500) from slickcharts. We need to to cautious with ticker conventions. Polygon uses a . with some share classes, such as BRK.B. Others have no points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSFT', 'AAPL', 'NVDA', 'AMZN', 'META']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500 = list(pd.read_excel('../output/universes/S&P500.xlsx', index_col=0)['Symbol'])\n",
    "sp500[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL', 'MSFT', 'GOOG', 'GOOGL', 'AMZN']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../output/universes/TOP_500.json', 'r') as f: \n",
    "    TOP_500 = json.load(f)\n",
    "TOP_500 = get_latest_value(TOP_500, date(2024, 3, 1))\n",
    "TOP_500 = [ticker[:-11] for ticker in TOP_500] # No need to remove the . in tickers like BRK.B as the S&P500 already contains these\n",
    "TOP_500[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at whether we even have all tickers that are in the S&P500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers in our list that match SP500: 498\n",
      "Tickers in SP500: 503\n"
     ]
    }
   ],
   "source": [
    "available = []\n",
    "for index, row in get_tickers(4).iterrows():\n",
    "    ticker = row['ID'][:-11]\n",
    "    if ticker in sp500:\n",
    "        available.append(ticker)\n",
    "\n",
    "difference = set(sp500).difference(set(available))\n",
    "print(f'Tickers in our list that match SP500: {len(set(available))}')\n",
    "print(f'Tickers in SP500: {len(sp500)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C', 'CAT', 'ETN', 'IVZ', 'JPM'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these tickers:\n",
    "* CPAY: Polygon does not have it for some unknown reason.\n",
    "* GEV: Newly listed, so this it is correct that we don't have that.\n",
    "* SOLV: Also newly listed.\n",
    "\n",
    "Do we have fundamental data for all S&P500 stocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals = pd.read_csv(DATA_PATH + 'processed/fundamentals.csv', index_col=0)\n",
    "tickers_we_have_fundamentals_of = list(set(fundamentals['ID']))\n",
    "tickers_we_have_fundamentals_of = [ticker[:-11] for ticker in tickers_we_have_fundamentals_of]\n",
    "\n",
    "not_available = []\n",
    "for ticker in sp500:\n",
    "    if ticker not in tickers_we_have_fundamentals_of:\n",
    "        not_available.append(ticker)\n",
    "len(not_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JPM', 'CAT', 'ETN', 'C', 'GEV', 'CPAY', 'SOLV', 'IVZ']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DAY: our data only starts in 2024-02, so it's correct that we do not have fundamentals yet. The reason our data only starts in 2024-02 is because we had no ticker change data for 2024 and DAY got renamed.\n",
    "\n",
    "For the other tickers, see the Russell 3000 section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tickers that are in S&P500 but not in Top 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sp500).difference(set(TOP_500)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(TOP_500).difference(set(sp500)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Russell 3000 vs Top 3000\n",
    "The Russell 3000 is essentially all stocks except the microcaps. I could not find the real holdings of the Russell 3000 so I will use the Russell 3000 ETF (IWV), which only has around 2750 holdings instead of 3000. Nevertheless, the 250 won't make a difference.\n",
    "\n",
    "First, not all tickers that we have are in IWV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2686\n"
     ]
    }
   ],
   "source": [
    "Russell_3000 = list(pd.read_csv('../output/universes/IWV_holdings.csv')['Ticker'])\n",
    "print(len(Russell_3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers in our list that match R3000: 2665\n",
      "Tickers in R3000: 2686\n"
     ]
    }
   ],
   "source": [
    "available = []\n",
    "for index, row in get_tickers(5).iterrows():\n",
    "    ticker = row['ID'][:-11]\n",
    "    ticker = ticker.replace('.', '')\n",
    "    if ticker in Russell_3000:\n",
    "        available.append(ticker)\n",
    "\n",
    "difference = set(Russell_3000).difference(set(available))\n",
    "print(f'Tickers in our list that match R3000: {len(set(available))}')\n",
    "print(f'Tickers in R3000: {len(Russell_3000)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually finding the cause:\n",
    "* ADRO = unlisted\n",
    "* SOLV = newly listed\n",
    "* WLLAW = warrants\n",
    "* WLLBW = warrants\n",
    "* PFC = probably because of corrupted file\n",
    "* METCV = ex-distribution\n",
    "* GEV = newly listed\n",
    "* CVR = contingent value right or something\n",
    "* CPAY = polygon does not have it?? Not even in most recent ticker list.\n",
    "* DHC = incorrect removed because 'trust' in name\n",
    "* KKR = incorrect removed\n",
    "* NXDT = incorrect removed because 'trust' in name\n",
    "* CG = incorrect classified\n",
    "\n",
    "I could manually correct these, but again I dont care about exact holdings. Having 99% accuracy is already very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at the difference between IWC and Top 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2686"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Russell_3000 = list(pd.read_csv('../output/universes/IWV_holdings.csv')['Ticker'])\n",
    "len(Russell_3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because IWV only has 2686 holdings, I will compare it to the top 2686. I will take July 2023, because the Russell 3000 is rebalanced in June and July is the closest of the data I have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/universes/TOP_2686.json', 'r') as f: \n",
    "    TOP_3000_all = json.load(f)\n",
    "TOP_3000 = get_latest_value(TOP_3000_all, date(2023, 7, 5))\n",
    "TOP_3000 = [ticker[:-11].replace('.', '') for ticker in TOP_3000] # IWC_holdings has no . in BRK.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tickers that are in IWC but not in Top 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Russell_3000).difference(set(TOP_3000)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = set(TOP_3000).difference(set(Russell_3000))\n",
    "len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_tickers()\n",
    "top_3000 = get_latest_value(TOP_3000_all, date(2023, 7, 5))\n",
    "tickers[tickers['ID'].isin(top_3000)].to_csv('../output/diff_R3000_T3000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers[tickers['ID'].isin(top_3000)].to_csv('../output/diff_R3000_T3000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A difference of 12% is quite OK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have fundamental data for all Russell 3000 stocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals = pd.read_csv(DATA_PATH + 'processed/fundamentals.csv', index_col=0)\n",
    "tickers_we_have_fundamentals_of = list(set(fundamentals['ID']))\n",
    "tickers_we_have_fundamentals_of = [ticker[:-11].replace('.', '') for ticker in tickers_we_have_fundamentals_of]\n",
    "\n",
    "not_available = []\n",
    "for ticker in Russell_3000:\n",
    "    if ticker not in tickers_we_have_fundamentals_of:\n",
    "        not_available.append(ticker)\n",
    "len(not_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the ones that we already have explained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = set(not_available).difference(difference)\n",
    "len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ARD', 'CPAY', 'GEV', 'SOLV', 'TBRG'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better than expected. I don't have ticker changes for 2024, so a part that could have explained the differences is that I failed to query on the old ticker.\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "All in all, I am content with the indices that I have created because they resemble the original indices enough for it to be usable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
