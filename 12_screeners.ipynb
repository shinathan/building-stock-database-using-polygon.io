{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import remove_extended_hours, get_market_dates, get_tickers, get_data, first_trading_date_after_equal\n",
    "from datetime import datetime, date, timedelta\n",
    "import mplfinance as mpf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import ast\n",
    "DATA_PATH = \"../../../data/polygon/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulating screeners\n",
    "In backtesting, we should be able to simulate what a screener would have given, else we would have to simulate all stocks simultaneously. Because this is a computationally expensive thing to do, the results are saved in the <code>processed/cache/</code> folder. There are of course some constraints to this. It should be technically possible to get the results from screeners, either online or via APIs (e.g. IBKR TWS). This means that intraday scanners are limited. For long-term screeners it does not matter because we can actually download everything after the end of the trading day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for calculating the most liquid N non-ADR stocks. This is to simulate the Russell or S&P indices. Of course there will be differences, but I care more about liquidity than whether it is precisely in an index or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_top_n_liquid(n=3000, start = date(2000, 1, 1), end = date(2100, 1, 1)):\n",
    "    tickers = get_tickers()\n",
    "    tickers = tickers[tickers['type'] == \"CS\"]\n",
    "    data = pd.DataFrame(index=get_market_dates())\n",
    "    IDs = []\n",
    "\n",
    "    quarterly_all = pd.DataFrame()\n",
    "    for index, id in enumerate(tickers['ID']):\n",
    "        bars = get_data(id, columns=['volume', 'close'], start=start, end=end)\n",
    "        quarterly = bars.resample('Q').agg({'close': 'last',\n",
    "                                'volume': 'sum'})\n",
    "        quarterly['turnover'] = quarterly['volume'] * quarterly['close']\n",
    "        quarterly = quarterly.rename(columns={'turnover': id}).drop(columns=['volume', 'close'])\n",
    "        quarterly_all = quarterly_all.merge(quarterly[id], how='outer', left_index=True, right_index=True)\n",
    "        #print(index)\n",
    "        \n",
    "        # Avoids defragmentation, increasing performance. Without this it would take more than 4x longer.\n",
    "        if index % 100 == 0:\n",
    "            quarterly_all = quarterly_all.copy()\n",
    "\n",
    "    for _, row in quarterly_all.copy().iterrows():\n",
    "        IDs.append(row[row.notna()].nlargest(n).index.tolist()) # Calculate largest N stocks, append to 'IDs'\n",
    "        \n",
    "    quarterly_all['IDs'] = IDs\n",
    "    quarterly_all = quarterly_all[['IDs']] # Get only the IDs\n",
    "    quarterly.index = quarterly.index + timedelta(days=1) # Get first day of new month to avoid look-ahead bias\n",
    "    quarterly.index = map(first_trading_date_after_equal, quarterly.index.date) # Get first trading day of new month\n",
    "\n",
    "    data = data.merge(quarterly_all, how='left', left_index=True, right_index=True) # Convert to daily\n",
    "    data = data.fillna(method='ffill')\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "\n",
    "    data.to_csv(DATA_PATH + f'processed/cache/top_{n}_liquid.csv')\n",
    "    return\n",
    "\n",
    "def get_top_n_liquid(day, n=3000):\n",
    "    if os.path.isfile(DATA_PATH + f'processed/cache/top_{n}_liquid.csv'):\n",
    "        data = pd.read_csv(DATA_PATH + f'processed/cache/top_{n}_liquid.csv', index_col=0)\n",
    "        data.index = pd.to_datetime(data.index).date\n",
    "        if data.index[-1] < day:\n",
    "            data = calculate_top_n_liquid(n)\n",
    "    else:\n",
    "        calculate_top_n_liquid(n)\n",
    "        data = pd.read_csv(DATA_PATH + f'processed/cache/top_{n}_liquid.csv', index_col=0)\n",
    "        data.index = pd.to_datetime(data.index).date\n",
    "    \n",
    "    return ast.literal_eval(data.loc[day, 'IDs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TSLA-2019-01-01', 'NVDA-2019-01-01', 'AAPL-2019-01-01', 'MSFT-2019-01-01', 'AMD-2019-01-01']\n"
     ]
    }
   ],
   "source": [
    "data = get_top_n_liquid(date(2023, 8, 25), n=500)\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top gainers %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Testing a mean-reversion strategy on SPY.\n",
    "I will try out a popular strategy using the IBS indicator. I want to see if I can match the results on [here](https://www.quantifiedstrategies.com/internal-bar-strength-ibs-indicator-strategy/). I will also use pure pandas.\n",
    "\n",
    "* Universe: SPY ETF\n",
    "* Entry: IBS < 0.2\n",
    "* Exit: IBS > 0.8\n",
    "* Trading on close prices.\n",
    "\n",
    "Although it is possible to get the exact closing price using market-on-close orders, you cannot know the value of the IBS at market close. So as an extension I will look at how the strategy has performed if the IBS is calculated using daily bars exluding the last minute.\n",
    "\n",
    "I also want to look at the impact of taxes (36%) and inflation.\n",
    "\n",
    "Note: I would not use the SPY for trading indices, because futures are more liquid. Even index CFDs may have lower trading costs. Also, I can only access US-domiciled ETFs from a very small amount of brokers due to stupid EU regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
