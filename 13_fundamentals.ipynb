{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals\n",
    "I don't really care what the exact point-in-time fundamental data is. Because that would imply updating my data at every earnings release. And my main use for fundamentals data is filtering/segmentation analysis. E.g. filter non profitable/non-profitable companies for a specific mean-reversion strategy. Or get the 3000 largest stocks by market cap. I am not interested in pure fundamental strategies, as the holding period will be months to years. And then 2003-2024 is simply not enough data.\n",
    "\n",
    "I will simply sample every quarter (after earnings releases) and then use that. Instead of having 1 file per ticker, we only need one fundamentals.csv file that contains everything. We can do this because the data is only updated quarterly so this file is small.\n",
    "\n",
    "The fundamentals.csv file:\n",
    "* Column 1: date (at Feb 1, May 1, Aug 1, Nov 1)\n",
    "* Column 2: current ticker (however we might need to query the old ticker, which we luckily have the information for in tickers v5)\n",
    "* Other columns:\n",
    "    * Market-cap\n",
    "    * SIC code\n",
    "\n",
    "Using market-cap, I can create historical constituents for S&P100, S&P500, S&P1500, Russell 3000 and Russell 3000E index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, time, timedelta\n",
    "from times import get_market_dates, get_market_calendar, last_trading_date_before\n",
    "from data import get_data\n",
    "from tickers import get_tickers\n",
    "from polygon.rest import RESTClient\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"../data/polygon/\"\n",
    "\n",
    "START_DATE = date(2019, 8, 1) # MUST BE 1st of FEB, MAY, AUG or NOV\n",
    "END_DATE = date(2024, 3, 1)\n",
    "\n",
    "with open(DATA_PATH + \"secret.txt\") as f:\n",
    "    KEY = next(f).strip()\n",
    "\n",
    "client = RESTClient(api_key=KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO CHANGE: at the date of a ticker change, also get the SIC and marketcap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [] # List of dictionaries, to eventually create a DataFrame\n",
    "tickers = get_tickers(types=['CS', 'ADRC'])\n",
    "for index, row in tickers.iterrows():\n",
    "    id = row['ID']\n",
    "    ticker = id[:-11]\n",
    "    asset_type = row['type']\n",
    "    start_data = row['start_data']\n",
    "    end_data = row['end_data']\n",
    "\n",
    "    # Get fundamental data for each quarter\n",
    "    for day in pd.date_range(START_DATE, END_DATE, freq='3MS').date:\n",
    "        # Stock must be active for the day we try to query fundamentals\n",
    "        if day < start_data or day > end_data:\n",
    "            continue\n",
    "\n",
    "        old_ticker = ticker\n",
    "        ticker_changes_str = tickers[tickers['ID'] == id]['tickers_old'].values[0]\n",
    "        ticker_changes = ast.literal_eval(ticker_changes_str)\n",
    "\n",
    "        # To get the point-in-time ticker, we need to search for the first ticker change after that date.\n",
    "        # (The ticker_changes always go from new to old. We reverse to go from old to new.)\n",
    "        ticker_changes = list(reversed(ticker_changes)) # Old to new now, e.g. [['2021-03-26', 'NTN'], ['2022-10-17', 'BTX']]\n",
    "\n",
    "        if len(ticker_changes) > 0:\n",
    "            for index, ticker_change in enumerate(ticker_changes):\n",
    "                ticker_change_date = ticker_change[0]\n",
    "                if day < date.fromisoformat(ticker_change_date):\n",
    "                    old_ticker = ticker_changes[index][1]\n",
    "                    break\n",
    "        try:\n",
    "            ticker_details = client.get_ticker_details(ticker=old_ticker, date=day)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            market_cap = ticker_details.market_cap\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            sic_code = ticker_details.sic_code\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        if not market_cap and not sic_code:\n",
    "            continue\n",
    "        \n",
    "        if not market_cap:\n",
    "            market_cap = np.nan\n",
    "        else:\n",
    "            market_cap_M =  int(market_cap/1_000_000)\n",
    "            \n",
    "        if not sic_code:\n",
    "            sic_code = np.nan\n",
    "        \n",
    "        # Add data to our list\n",
    "        rows.append({'date': day,\n",
    "                     'ID': id,\n",
    "                     'market_cap_M': market_cap_M,\n",
    "                     'sic_code': sic_code,\n",
    "                     'type': asset_type})\n",
    "    \n",
    "    market_cap_df = pd.DataFrame(rows)\n",
    "    market_cap_df = market_cap_df.groupby('ID').agg({'market_cap_M': 'last'})\n",
    "    print(f'{index+1} | {len(market_cap_df)}')\n",
    "\n",
    "market_cap_df = pd.DataFrame(rows)\n",
    "market_cap_df.to_csv(DATA_PATH + 'processed/fundamentals.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "96.5% of stocks have market cap data and 83% has sic codes. Let's look at the stocks that don't. (We will filter on stocks that have a history larger than 60 days, because for short listings there won't be fundamental data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_tickers(types=['CS', 'ADRC'])\n",
    "tickers = tickers[tickers['end_data'] - tickers['start_data'] > timedelta(days=60)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of tickers: 7495\n",
      "Amount of stocks with marketcap: 7337\n",
      "Amount of stocks with SIC code: 6189\n"
     ]
    }
   ],
   "source": [
    "fundamentals = pd.read_csv(DATA_PATH + 'processed/fundamentals.csv', index_col=0)\n",
    "grouped_by_marketcap = fundamentals.groupby('ID').agg({'market_cap_M': 'last'}).dropna()\n",
    "grouped_by_sic = fundamentals.groupby('ID').agg({'sic_code': 'last'}).dropna()\n",
    "\n",
    "print(f'Amount of tickers: {len(tickers)}')\n",
    "print(f\"Amount of stocks with marketcap: {len(grouped_by_marketcap)}\")\n",
    "print(f\"Amount of stocks with SIC code: {len(grouped_by_sic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_market_cap_tickers = []\n",
    "no_SIC_tickers = []\n",
    "for index, row in get_tickers().iterrows():\n",
    "    id = row['ID']\n",
    "    if id not in grouped_by_marketcap.index:\n",
    "        no_market_cap_tickers.append(id)\n",
    "    if id not in grouped_by_sic.index:\n",
    "        no_SIC_tickers.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_market_cap = tickers[tickers['ID'].isin(no_market_cap_tickers)]\\\n",
    "    [['ID', 'name', 'start_data', 'end_data', 'type', 'cik', 'composite_figi']]\n",
    "no_market_cap.to_csv('../output/no_marketcap.csv')\n",
    "\n",
    "no_SIC = tickers[tickers['ID'].isin(no_SIC_tickers)]\\\n",
    "    [['ID', 'name', 'start_data', 'end_data', 'type', 'cik', 'composite_figi']]\n",
    "no_SIC.to_csv('../output/no_SIC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When manually looking through the tickers with no SIC codes, almost all of them are foreign companies (but not ADRs).** It is not clear why they don't have SIC codes. Also the location is always 'us', even for foreign-headquartered corporations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updates\n",
    "1. There is no need to process ticker changes because fundamentals is point-in-time. If we get fundamental data for a ticker that had a ticker change, the code automatically searchs for the old ticker.\n",
    "2. Same procedure to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polygon.rest import RESTClient\n",
    "\n",
    "with open(DATA_PATH + \"secret.txt\") as f:\n",
    "    KEY = next(f).strip()\n",
    "\n",
    "client = RESTClient(api_key=KEY)\n",
    "\n",
    "data = pd.DataFrame(client.vx.list_stock_financials(cik = 'AAPL', filing_date_gte=date(2014, 1, 1), filing_date_lte=date(2016, 1, 1)) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
